# MeetingNotes - Intelligent Meeting Analysis with Voxtral

Web application using **Voxtral AI from Mistral AI** to automatically analyze your audio/video meetings with:
- **Direct analysis**: Transcription and structured summary in one step
- **3 processing modes**: Local (Transformers), MLX (Apple Silicon), API (Cloud)
- **Quantized models**: 4bit/8bit support for memory efficiency
- **Smart diarization**: Speaker identification and renaming
- **Customizable summaries**: Modular sections according to your needs
- **Language-adaptive**: Automatically detects and responds in meeting language
- **Centralized UI**: Clean English interface with multilingual analysis
- **ğŸš€ Hugging Face Spaces**: Try the simplified version online at [VincentGOURBIN/MeetingNotes-Voxtral-Analysis](https://huggingface.co/spaces/VincentGOURBIN/MeetingNotes-Voxtral-Analysis)

![Meeting Analysis Interface](assets/meeting%20analysis%20parameters.png)

## ğŸš€ Quick Start

### ğŸŒ Online Version (Hugging Face Spaces)
Try MeetingNotes directly in your browser: **[VincentGOURBIN/MeetingNotes-Voxtral-Analysis](https://huggingface.co/spaces/VincentGOURBIN/MeetingNotes-Voxtral-Analysis)**

*This simplified version uses standard Mistral Voxtral models optimized for Zero GPU with automatic chunk processing.*

### ğŸ’» Local Installation (Full Version)

1. **Clone the repository and install dependencies:**
```bash
git clone <repository-url>
cd meetingnotes
python install.py
```

**Note:** The installation script automatically:
- Creates a virtual environment (`.venv`) to isolate dependencies
- Detects AMD GPUs on Linux and installs PyTorch with ROCm support when available
- Installs all required packages within the virtual environment

2. **Activate the virtual environment:**

On Linux/macOS:
```bash
source .venv/bin/activate
```

On Windows (Command Prompt):
```bash
.venv\Scripts\activate.bat
```

On Windows (PowerShell):
```bash
.venv\Scripts\Activate.ps1
```

3. **Configure your Hugging Face token:**
```bash
cp .env.example .env
# Edit .env and add your Hugging Face token
```

4. **Launch the application:**
```bash
python main.py
```

The web interface will be accessible at **http://localhost:7860**

**Note:** Remember to activate the virtual environment each time you want to run the application. To deactivate it when done, simply run `deactivate`.

## ğŸ³ Docker Usage

The application can be containerized for easy deployment across different environments. Three Docker configurations are provided to support different hardware backends:

### ROCm Backend (AMD GPUs)
```bash
docker compose -f docker/docker-compose.rocm.yml up --build
```

### CUDA Backend (NVIDIA GPUs)
```bash
docker compose -f docker/docker-compose.cuda.yml up --build
```

### CPU Backend
```bash
docker compose -f docker/docker-compose.cpu.yml up --build
```

## âš™ï¸ Configuration

### Hugging Face Token (Required)
Get an access token from [Hugging Face](https://huggingface.co/settings/tokens) and add it to `.env`:
```env
HUGGINGFACE_TOKEN=your_token_here
```

### Mistral API Key (Optional)
To use cloud API mode, get a key from [Mistral AI](https://console.mistral.ai/):
```env
MISTRAL_API_KEY=your_mistral_api_key
```

## ğŸ¯ Features

### Processing Modes

Choose the mode that best fits your hardware and needs:

#### Local Mode (Transformers)
![Local Mode](assets/local%20mode.png)
- **Local processing**: Everything runs on your machine with PyTorch
- **Privacy**: No data sent to external servers
- **GPU acceleration**: Automatic CUDA/MPS detection

#### ROCm Mode (AMD GPUs)
- **AMD GPU acceleration**: Optimized for AMD GPUs with ROCm support
- **Local processing**: Everything runs on your machine with PyTorch
- **Automatic detection**: Install script detects AMD GPUs and configures ROCm

#### MLX Mode (Apple Silicon)
![MLX Mode](assets/mlx%20mode.png)
- **Optimized for Mac**: M1/M2/M3 processors with MLX Framework
- **Best performance**: Native Apple Silicon acceleration
- **Memory efficient**: Optimized quantized models

#### API Mode (Cloud)
![API Mode](assets/api%20mode.png)
- **Cloud processing**: Uses Mistral Cloud API
- **No local resources**: Minimal memory usage
- **Always up-to-date**: Latest models and improvements

### Models and Quantization
| Model | Precision | Repository | Memory Usage |
|-------|-----------|------------|------------|
| **Voxtral Mini** | Default | `mistralai/Voxtral-Mini-3B-2507` | ~6GB |
| **Voxtral Mini** | 8bit | `mzbac/voxtral-mini-3b-8bit` | ~3.5GB |
| **Voxtral Mini** | 4bit | `mzbac/voxtral-mini-3b-4bit-mixed` | ~2GB |
| **Voxtral Small** | Default | `mistralai/Voxtral-Small-24B-2507` | ~48GB |
| **Voxtral Small** | 8bit | `VincentGOURBIN/voxtral-small-8bit` | ~24GB |
| **Voxtral Small** | 4bit | `VincentGOURBIN/voxtral-small-4bit-mixed` | ~12GB |

### Speaker Diarization

![Speaker Diarization](assets/diarization.png)

- **Automatic identification**: Detection of different speakers with pyannote.audio
- **Reference segments**: Listen to audio samples for each speaker
- **Custom renaming**: Assign human names to speakers
- **Context integration**: Use speaker information in summaries

### Customizable Summaries
**Modular sections**: Choose the sections to include according to your needs
- **ğŸ“„ Executive Summary**: Global overview of the meeting
- **ğŸ’¬ Main Discussions**: Main topics addressed
- **âœ… Action Plan**: Actions, responsibilities, deadlines
- **âš–ï¸ Decisions Made**: Validated decisions
- **â­ï¸ Next Steps**: Follow-up actions
- **ğŸ“Œ Main Topics**: Information presented
- **â­ Key Points**: Insights and key data
- **â“ Questions & Discussions**: Questions asked and answers
- **ğŸ“ Follow-up Elements**: Clarifications needed

**Predefined Profiles**:
- **ğŸ¯ Action Profile**: Focus on tasks and decisions
- **ğŸ“Š Information Profile**: Focus on data and insights
- **ğŸ“‹ Complete Profile**: All sections activated

### Supported Formats
- **Audio**: WAV, MP3, M4A, OGG, FLAC
- **Video**: MP4, AVI, MOV, MKV (automatic audio extraction)

## ğŸ”§ Usage

### 1. Processing Mode Configuration
1. **Choose the mode**: Local, MLX or API
2. **Select the model**: Mini or Small according to your needs
3. **Choose precision**: Default, 8bit or 4bit to optimize memory

### 2. Upload and Options
- **File**: Direct audio or video (automatic extraction)
- **Optional trimming**: Start/end trimming (leave empty for 0)
![Trim Options](assets/trim_options.png)
- **Chunk size**: Processing duration (5-25 minutes)

### 3. Diarization (Optional)
1. **Analyze speakers** with pyannote.audio
2. **Listen to reference segments** of each speaker
3. **Rename speakers** with custom names
4. **Apply renamings** for enriched context

### 4. Summary Customization
- **Modular sections**: Enable only necessary sections
- **Quick profiles**: Action, Information or Complete
- **Flexible configuration**: Adapt summary to your usage

### 5. Analysis and Results
Click **"Analyze Meeting"** to get a customized structured summary.

![Meeting Summary](assets/meeting%20summary.png)

## ğŸ—ï¸ Architecture

The project follows a modular architecture with two versions:

### Main Project (`src/meetingnotes/`)
```
src/meetingnotes/
â”œâ”€â”€ ai/                    # Artificial Intelligence
â”‚   â”œâ”€â”€ voxtral_analyzer.py      # Local Voxtral analyzer (Transformers)
â”‚   â”œâ”€â”€ voxtral_api_analyzer.py  # Voxtral API analyzer
â”‚   â”œâ”€â”€ voxtral_mlx_analyzer.py  # Voxtral MLX analyzer (Apple Silicon)
â”‚   â”œâ”€â”€ diarization.py           # Speaker diarization (pyannote)
â”‚   â”œâ”€â”€ memory_manager.py        # Optimized memory management
â”‚   â””â”€â”€ prompts_config.py        # Centralized prompt configuration
â”œâ”€â”€ audio/                 # Audio Processing
â”‚   â”œâ”€â”€ wav_converter.py         # Format conversion
â”‚   â””â”€â”€ normalizer.py            # Volume normalization
â”œâ”€â”€ core/                  # Business Logic
â”‚   â”œâ”€â”€ voxtral_direct.py        # Direct processing (Transformers)
â”‚   â”œâ”€â”€ voxtral_api.py           # Mistral API interface
â”‚   â””â”€â”€ voxtral_mlx.py           # MLX Apple Silicon interface
â”œâ”€â”€ ui/                    # User Interface
â”‚   â”œâ”€â”€ main.py                  # Main Gradio interface
â”‚   â”œâ”€â”€ handlers.py              # Event handlers
â”‚   â”€â”€ labels.py                # UI labels and text constants
â””â”€â”€ utils/                 # Utilities
    â”œâ”€â”€ __init__.py              # Utils module
    â”œâ”€â”€ time_formatter.py        # Duration formatting
    â””â”€â”€ token_tracker.py          # Token usage tracking
```

### Hugging Face Spaces Version (`huggingface-space/`)
Simplified version deployed at [VincentGOURBIN/MeetingNotes-Voxtral-Analysis](https://huggingface.co/spaces/VincentGOURBIN/MeetingNotes-Voxtral-Analysis):
```
huggingface-space/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ ai/
â”‚   â”‚   â”œâ”€â”€ voxtral_spaces_analyzer.py   # HF Spaces optimized analyzer
â”‚   â”‚   â””â”€â”€ prompts_config.py            # Shared prompts configuration
â”‚   â”œâ”€â”€ ui/
â”‚   â”‚   â”œâ”€â”€ spaces_interface.py          # Simplified Gradio interface
â”‚   â”‚   â””â”€â”€ labels.py                    # UI labels
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ zero_gpu_manager.py          # Zero GPU management
â”‚       â””â”€â”€ token_tracker.py             # Token tracking
â”œâ”€â”€ app.py                               # HF Spaces entry point
â”œâ”€â”€ requirements.txt                     # HF Spaces dependencies
â””â”€â”€ deploy.py                           # Deployment script
```

**Key differences in HF Spaces version:**
- Only Transformers backend (no MLX/API modes)
- Standard Mistral Voxtral models (optimized for Zero GPU)
- No speaker diarization (simplified interface)
- Progress bar with chunk-based tracking
- Automatic chunk duration optimization (15min Mini, 10min Small)

For more details, see [ARCHITECTURE.md](ARCHITECTURE.md).

## ğŸ”§ Advanced Configuration

### Environment Variables
```env
# Required for all modes
HUGGINGFACE_TOKEN=your_hf_token

# Optional for API mode
MISTRAL_API_KEY=your_mistral_key
```

### Hardware Optimizations
- **Mac M1/M2/M3**: Use MLX mode for better performance
- **NVIDIA GPU**: Local mode with automatic CUDA acceleration
- **AMD GPU**: ROCm mode with automatic GPU detection (Linux only)
- **CPU only**: Prefer 4bit models to save memory
- **Limited memory**: Mini 4bit (~2GB) or Small 4bit (~12GB)

## ğŸ” Technical Features

### Memory Optimizations
- **Pre-quantized models**: 4bit and 8bit for memory reduction
- **Memory manager**: Automatic cleanup between chunks
- **Multi-platform support**: MPS (Apple), CUDA (NVIDIA), optimized CPU

### Intelligent Processing
- **3 inference modes**: Direct audio-chat without intermediate transcription  
- **Language-adaptive**: Automatically detects meeting language and responds accordingly
- **Adaptive chunks**: Smart division of long files with synthesis
- **Modular prompts**: Customizable summary sections with centralized configuration
- **Enriched context**: Integration of diarization in analyses
- **Token tracking**: Comprehensive usage statistics across all processing modes

### Modern Interface
- **Centralized UI labels**: Clean English interface with maintainable text management
- **Improved API layout**: API key positioned next to model selection for better UX
- **Interactive diarization**: Speaker listening and renaming
- **Modular sections**: Advanced summary customization with preset profiles
- **Real-time feedback**: Detailed progress indicators and token consumption tracking

## ğŸ“¦ Main Dependencies

- **gradio**: Modern web user interface
- **torch/torchaudio**: Deep learning framework (Local mode)
- **transformers**: Hugging Face and Voxtral models
- **mlx/mlx-voxtral**: MLX framework optimized for Apple Silicon (macOS only)
- **pyannote.audio**: Speaker diarization
- **pydub**: Audio processing and conversion
- **requests**: Communication with Mistral API
- **python-dotenv**: Environment variables management

## ğŸ”’ Security and Privacy

- **Local processing**: Option for entirely on-machine processing
- **Environment variables**: Secure tokens via `.env`
- **No cloud storage**: Your files remain local
- **Automatic cleanup**: Temporary files removal

## ğŸš¦ Project Status

âœ… **Version v2.2** - Hugging Face Spaces Integration
- **ğŸš€ HF Spaces version**: Simplified online version at [VincentGOURBIN/MeetingNotes-Voxtral-Analysis](https://huggingface.co/spaces/VincentGOURBIN/MeetingNotes-Voxtral-Analysis)
- **3 processing modes**: Local, MLX, API with improved layout (main version)
- **Standard Mistral models**: Original Voxtral models optimized for Zero GPU (HF Spaces)
- **6 model configurations**: Mini/Small + Default/8bit/4bit (main version)
- **Complete diarization**: Speaker identification and renaming (main version only)
- **Modular summaries**: 9 customizable sections with preset profiles
- **Language-adaptive AI**: Automatically responds in detected meeting language
- **Progress tracking**: Real-time progress bar with chunk-based updates
- **Centralized UI management**: Clean English interface with maintainable labels
- **Token tracking**: Comprehensive usage statistics for all modes
- **Improved UX**: Better API mode layout and visual organization
- **Multi-platform support**: Windows, macOS, Linux (main), Zero GPU (HF Spaces)

## ğŸ¤ Contributing

To contribute to the project:
1. Fork the repository
2. Create a feature branch
3. Implement your changes
4. Add tests if necessary
5. Open a Pull Request

## ğŸ“„ License

This project is under MIT license. See the LICENSE file for more details.

---
**MeetingNotes** - Powered by [Voxtral from Mistral AI](https://mistral.ai/) | ğŸš€ Intelligent meeting analysis | ğŸ’¾ Secure local and cloud processing